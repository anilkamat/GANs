from doctest import OPTIONFLAGS_BY_NAME
from turtle import shape
import matplotlib.pyplot as plt
import numpy as np
from numpy.random import uniform
from keras.models import Sequential

x_min = -5
x_max = 5
sample_len = 64
sample_size = 32768
COOR = np.linspace(x_min,x_max,sample_len)

# a sin(bx+c)
samples = np.zeros((sample_size,sample_len))
for i in range(10):
    a = uniform(0.1,2)
    b = uniform(0.1,2)
    c = np.random.uniform(2.0)
    samples[i] = np.array([np.sin(b*x+c) for x in COOR])
    #plt.plot(COOR, uniform(0.1,2)*np.sin(uniform(0.2,2.0)*COOR)+np.random.uniform(2))

#plot some curves

# fig, axis = plt.subplots(1,1)
# for i in range(5):
#     #axis.plot(COOR,samples[i])

#discriminators
from tensorflow.keras import layers
import tensorflow.keras as keras

discriminator_Input = keras.Input(shape=(sample_len), name= 'discriminator')
out1 = layers.Dense(sample_len, activation = 'relu') (discriminator_Input)
out2 = layers.Dropout(0.5) (out1)
out3 = layers.Dense(16, activation = 'relu') (out2)
discriminator_output = layers.Dense(1, activation = 'relu') (out3)
discriminator = keras.Model(discriminator_Input,discriminator_output, name = 'discriminator')
#discriminator.summary()
discriminator.compile(loss = keras.losses.BinaryCrossentropy(from_logits= True),
    optimizer = keras.optimizers.Adam(learning_rate=0.01),metrics = ["accuracy"])

#generator
generator_Input = keras.Input(shape=(sample_len), name= 'generator')
out1 = layers.Dense(sample_len, activation = 'relu') (generator_Input)
out2 = layers.Dense(16, activation = 'relu') (out1)
generator_output = layers.Dense(sample_len, activation = 'tanh') (out2)
generator = keras.Model(generator_Input,generator_output, name = 'generator')
#generator.summary()
generator.compile(loss = keras.losses.MeanSquaredError(),
    optimizer = keras.optimizers.Adam(learning_rate=0.01),metrics = ["accuracy"])

#GAN
gan = Sequential()
gan.add(generator)
gan.add(discriminator)
gan.compile(loss = keras.losses.BinaryCrossentropy (from_logits=True), 
        optimizer= keras.optimizers.Adam(learning_rate= 0.01),metrics = ['accuracy'])
#gan.summary()

#Training

epochs = 60
batch = 16
noise = uniform(x_min,x_max, size=(sample_size,sample_len))
ones = np.ones((sample_size))
zeros = np.zeros((sample_size))
print('epoch | dis.loss |dis.acc | gen.loss | gen.acc ')
print('......+..........+........+..........+.........')
fig = plt.figure(figsize=(8,12))
ax_index = 1

for e in range(epochs):
    for k in range(sample_size//batch):
        n = np.random.randint(0,sample_size, size = batch)
        p = generator.predict(noise[n])
        x = np.concatenate((p,samples[n]))
        y = np.concatenate((zeros[n],ones[n]))
        d_result = discriminator.train_on_batch(x,y)
        discriminator.trainable = False
        g_result = gan.train_on_batch(noise[n], ones[n])
        discriminator.trainable = True
    print(f" {e:04n} |  {d_result[0]:.5f}  |  {d_result[1]:.5f} |  {g_result[0]:.5f}  |  {d_result[1]:.5f}")
    if e % 10 == 3:
        ax = fig.add_subplot(8, 1, ax_index)
        plt.plot(COOR, p[-1])
        ax.xaxis.set_visible(False)
        plt.ylabel(f"Epoch: {e}")
        ax_index += 1

# Plots a curve generated by the GAN
y = generator.predict(uniform(x_min, x_max, size = (1, sample_len)))[0]
ax = fig.add_subplot(8, 1, ax_index)
plt.plot(COOR, y)